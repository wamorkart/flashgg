* H4Gamma

** Cloning the repository


   #+BEGIN_EXAMPLE
   export SCRAM_ARCH=slc7_amd64_gcc700
   cmsrel CMSSW_10_6_8
   cd CMSSW_10_6_8/src
   cmsenv
   git cms-init
   cd $CMSSW_BASE/src
   git clone -b h4g_withPreFireWeightApplied git@github.com:wamorkart/flashgg.git
   source flashgg/setup_flashgg.sh
   #+END_EXAMPLE

   If everything now looks reasonable, you can build:
   #+BEGIN_EXAMPLE
   cd $CMSSW_BASE/src
   scram b -j 9
   #+END_EXAMPLE

** Setting up a voms Proxy

To access grid files to run the tagger on, you must run the following commands:

    #+BEGIN_EXAMPLE
    cmsenv
    voms-proxy-init --voms cms --valid 168:00
    #+END_EXAMPLE

after the voms command, you should receive an output similar to:

    #+BEGIN_EXAMPLE
    Created proxy in /tmp/x509up_u95168
    #+END_EXAMPLE

to set this proxy to your X509_USER_PROXY environment variable for the example above, simply use the command:

    #+BEGIN_EXAMPLE
    . proxy.sh x509up_u95168
    #+END_EXAMPLE

where x590up_u95168 would be replaced by whatever your proxy name is.


** H4G CandidateDumper to produce Vtx trainign ntuples

*** Running locally
    #+BEGIN_EXAMPLE
    cmsRun Taggers/test/H4GTest_cfg.py vtxBDTDumper=1 isCondor=0 year=2018 isSignal=1 mass=60 metaConditions=$CMSSW_BASE/src/flashgg/MetaData/data/MetaConditions/Era2018_RR-17Sep2018_v1.json doH4GVertex=1 doPdfWeights=0
    #+END_EXAMPLE

*** Running on condor
      #+BEGIN_EXAMPLE
      fggRunJobs.py --load Taggers/test/H4G_2018_Tagger/H4G_VtxTrees.json -D -P -n 500 -d 2018_vtx -x cmsRun Taggers/test/H4GTest_cfg.py --no-copy-proxy  maxEvents=-1 -q workday --stage-to /eos/user/t/twamorka/h4g_fullRun2/2018_VtxTrees/
      #+END_EXAMPLE


** H4G Tagger

*** Running Locally

The H4G Tagger can be run locally on signal with:

    #+BEGIN_EXAMPLE
    cmsRun Systematics/test/workspaceStd.py metaConditions=MetaData/data/MetaConditions/Era2016_RR-17Jul2018_v1.json campaign=H4G_2016_SignalCustomization_October2020 dataset=HAHMHToAA_AToGG_MA-15GeV_TuneCUETP8M1_PSweights_13TeV-madgraph_pythia8 doH4GTag=1 H4GTagsOnly=1 maxEvents=500 doSystematics=1 dumpWorkspace=0 dumpTrees=1  useAAA=1 useParentDataset=1 analysisType=lowMassAnalysis doPdfWeights=0
    #+END_EXAMPLE

and on data:
    #+BEGIN_EXAMPLE
    cmsRun Systematics/test/workspaceStd.py metaConditions=MetaData/data/MetaConditions/Era2016_RR-17Jul2018_v1.json campaign=Era2016_RR-17Jul2018_v2 dataset=/DoubleEG/spigazzi-Era2016_RR-17Jul2018_v2-legacyRun2FullV1-v0-Run2016H-17Jul2018-v1-86023db6be00ee64cd62a3172358fb9f/USER doH4GTag=1 H4GTagsOnly=1 maxEvents=500 doSystematics=1 dumpWorkspace=0 dumpTrees=1 useAAA=1 processId=Data processType=Data useParentDataset=1 analysisType=lowMassAnalysis doPdfWeights=0
    #+END_EXAMPLE


*** Running on condor 2018 signal samples

   Change the --stage-to option to the folder where you want the output root files to land

    #+BEGIN_EXAMPLE
    fggRunJobs.py --load Taggers/test/H4G_2018_Tagger/H4G_Signal.json -D -P -n 200 -d H4G_2018 -x cmsRun Systematics/test/workspaceStd.py -q tomorrow --no-copy-proxy analysisType=lowMassAnalysis maxEvents=-1 --stage-to /eos/user/t/twamorka/H4G_Signal_Campaign_18Jan2021/2018/  --make-light-tarball
    #+END_EXAMPLE



*** Resubmitting missing jobs
    #+BEGIN_EXAMPLE
    python Systematics/scripts/resubmit_jobs.py -d <directory originally created by fggRunJobs> -s <directory where the jobs were staged to>
    #+END_EXAMPLE
