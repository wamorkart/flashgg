* H4Gamma

** Cloning the repository


   #+BEGIN_EXAMPLE
   export SCRAM_ARCH=slc7_amd64_gcc700
   cmsrel CMSSW_10_5_0
   cd CMSSW_10_5_0/src
   cmsenv
   git cms-init
   cd $CMSSW_BASE/src
   git clone -b h4g_tagger_dev_2016 git@github.com:wamorkart/flashgg.git
   source flashgg/setup_flashgg.sh
   #+END_EXAMPLE

   If everything now looks reasonable, you can build:
   #+BEGIN_EXAMPLE
   cd $CMSSW_BASE/src
   scram b -j 4
   #+END_EXAMPLE

** Setting up a voms Proxy

To access grid files to run the tagger on, you must run the following commands:

    #+BEGIN_EXAMPLE
    cmsenv
    voms-proxy-init --voms cms --valid 168:00
    #+END_EXAMPLE

after the voms command, you should receive an output similar to:

    #+BEGIN_EXAMPLE
    Created proxy in /tmp/x509up_u95168
    #+END_EXAMPLE

to set this proxy to your X509_USER_PROXY environment variable for the example above, simply use the command:

    #+BEGIN_EXAMPLE
    . proxy.sh x509up_u95168
    #+END_EXAMPLE

where x590up_u95168 would be replaced by whatever your proxy name is.

** H4G Tagger

*** Running Locally

The H4G Tagger can be run locally on signal with:

    #+BEGIN_EXAMPLE
    cmsRun Systematics/test/workspaceStd.py metaConditions=MetaData/data/MetaConditions/Era2016_RR-17Jul2018_v1.json campaign=H4GandHH4G_2016_27Sep2019 dataset=SUSYGluGluToHToAA_AToGG_M-60_TuneCUETP8M1_13TeV_pythia8 doH4GTag=1 H4GTagsOnly=1 maxEvents=500 doSystematics=1 dumpWorkspace=0 dumpTrees=1  useAAA=1 useParentDataset=1 analysisType=lowMassAnalysis
    #+END_EXAMPLE

and on data:
    #+BEGIN_EXAMPLE
    cmsRun Systematics/test/workspaceStd.py metaConditions=MetaData/data/MetaConditions/Era2016_RR-17Jul2018_v1.json campaign=Era2016_RR-17Jul2018_v2 dataset=/DoubleEG/spigazzi-Era2016_RR-17Jul2018_v2-legacyRun2FullV1-v0-Run2016H-17Jul2018-v1-86023db6be00ee64cd62a3172358fb9f/USER doH4GTag=1 H4GTagsOnly=1 maxEvents=500 doSystematics=1 dumpWorkspace=0 dumpTrees=1 useAAA=1 processId=Data processType=Data useParentDataset=1 analysisType=lowMassAnalysis
    #+END_EXAMPLE

*** Running on condor

   Change the --stage-to option to the folder where you want the output root files to land

    #+BEGIN_EXAMPLE
    fggRunJobs.py --load Taggers/test/H4G_2016_Tagger/H4G_Signal1.json -D -P -n 500 -d Tagger_Signal1_2016 -x cmsRun Systematics/test/workspaceStd.py -q workday --no-copy-proxy analysisType=lowMassAnalysis maxEvents=-1 --stage-to /eos/user/t/twamorka/Tagger_21Jun2020/
    fggRunJobs.py --load Taggers/test/H4G_2016_Tagger/H4G_Signal2.json -D -P -n 500 -d Tagger_Signal2_2016 -x cmsRun Systematics/test/workspaceStd.py -q workday --no-copy-proxy analysisType=lowMassAnalysis maxEvents=-1 --stage-to /eos/user/t/twamorka/Tagger_21Jun2020/
    fggRunJobs.py --load Taggers/test/H4G_2016_Tagger/H4G_Signal3.json -D -P -n 500 -d Tagger_Signal3_2016 -x cmsRun Systematics/test/workspaceStd.py -q workday --no-copy-proxy analysisType=lowMassAnalysis maxEvents=-1 --stage-to /eos/user/t/twamorka/Tagger_21Jun2020/


    #+END_EXAMPLE

and on data:
    #+BEGIN_EXAMPLE
    fggRunJobs.py --load Taggers/test/H4G_2016_Tagger/H4G_Data1.json -D -P -n 500 -d Tagger_Data1_2016 -x cmsRun Systematics/test/workspaceStd.py -q workday --no-copy-proxy analysisType=lowMassAnalysis maxEvents=-1 --stage-to /eos/user/t/twamorka/Tagger_21Jun2020/
    fggRunJobs.py --load Taggers/test/H4G_2016_Tagger/H4G_Data2.json -D -P -n 500 -d Tagger_Data2_2016 -x cmsRun Systematics/test/workspaceStd.py -q workday --no-copy-proxy analysisType=lowMassAnalysis maxEvents=-1 --stage-to /eos/user/t/twamorka/Tagger_21Jun2020/
    fggRunJobs.py --load Taggers/test/H4G_2016_Tagger/H4G_Data3.json -D -P -n 500 -d Tagger_Data3_2016 -x cmsRun Systematics/test/workspaceStd.py -q workday --no-copy-proxy analysisType=lowMassAnalysis maxEvents=-1 --stage-to /eos/user/t/twamorka/Tagger_21Jun2020/

    #+END_EXAMPLE

*** Resubmitting missing jobs
    #+BEGIN_EXAMPLE
    python Systematics/scripts/resubmit_jobs.py -d <directory originally created by fggRunJobs> -s <directory where the jobs were staged to>
